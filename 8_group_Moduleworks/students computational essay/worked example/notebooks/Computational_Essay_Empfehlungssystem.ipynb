{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computational Essay – Entwicklung eines Film-Empfehlungssystems\n",
    "<div class = \"alert alert-warning\">\n",
    "    <h3>Meta-Bemerkung</h3>\n",
    "    Das hier ist ein Beispiel für einen <b>Computational Essay</b> in Form eines Jupyter Notebooks.\n",
    "    In diesem Computational Essay wird ein beispielhafter mathematischer Modellierungsprozess zu einer realen Problemstellung mit exemplarischen Daten und Modellierungsansätzen gezeigt. Welche Ansätze man entwickelt und umsetzt, hängt  von der <b>Problemstellung</b> ab, die beantwortet werden soll.<br><br>\n",
    "\n",
    "Dieses Jupyter Notebook soll zeigen, wie ein Computational Essay aufgebaut sein kann. Es kann als Vorlage für eigene Computational Essays benutzt werden. Wichtig sind neben den Codezellen insbesondere Zellen mit:\n",
    "    <ul>\n",
    "        <li><b>Erklärungen</b>, die beschreiben, wie ihr beim Modellieren vorgegangen seid,</li>\n",
    "        <li><b>Interpretationen der Ergebnisse</b>, insbesondere im Hinblick auf das reale Problem,</li>\n",
    "        <li><b>Erläuterungen zum verwendeten Programmcode</b> und ggf. zu benutzten Bibliotheken.</li>\n",
    "    </ul>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"../figs/Modellierungskreislauf.png\" width=\"950\"/> \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<div class = \"alert alert-warning\">\n",
    "    Ein Computational Essay zur Bearbeitung eines realen Problems enthält im Wesentlichen die folgenden Elemente, die sich auch im Modellierungskreislauf wiederfinden.\n",
    "     <ul>\n",
    "        <li><b>Problembeschreibung:</b> Hier wird erläutert, worum es geht und wieso es sich um ein relevantes Thema handelt</li>\n",
    "        <ul>\n",
    "            <li><b>Fragestellung:</b> In der Problembeschreibung wird eine Forschungsfrage formuliert, die mit dem Computational Essay beantwortet werden soll. Dazu können auch Unterfragen gestellt werden.</li>\n",
    "            </ul>\n",
    "        <li><b>Daten:</b> Hier werden gegebene Daten in das Jupyter Notebook geladen. <span style=\"color:black\">Achtung: nicht zu jedem Problem gibt es Daten als Ausgangspunkt. Dieser Teil entfällt womöglich. </span> \n",
    " </li>\n",
    "        <ul>\n",
    "            <li><b>Datenerkundung und Visualisierung:</b> Hier beginnt die Analyse der Daten im Hinblick auf die Forschungsfrage. Interpretationen der Beobachtungen und Erkenntnisse sind hier wichtig!</li>\n",
    "            <li><b>Datenvorbereitung:</b> Zum Teil stößt man  bei der ersten Datenerkundung auf fehlerhafte oder fehlende Daten. Die Daten werden dann entsprechend vorbereitet (bspw. Datenpunkte entfernt). Die Datenvorbereitungsschritte werden dokumentiert und begründet.</li>\n",
    "        </ul>\n",
    "        <li><b>Erster Modellansatz:</b> Hier wird der erste Modellansatz verständlich beschrieben.</li>\n",
    "        <ul>\n",
    "            <li><b>Vereinfachungen und Modellannahmen:</b> Vielfach sind die Probleme so komplex, dass Vereinfachungen vorgenommen oder Annahmen getroffen werden müssen. Diese werden gut dokumentiert.</li>\n",
    "            <li><b>Entwicklung und Beschreibung des mathematischen Modells:</b> Hier wird das entwickelte mathematische Modell beschrieben. </li>\n",
    "            <li><b>Computergestützte Berechnungen:</b> Die Berechnung  mathematischer Lösungen wird mit Programmiercode umgesetzt. Auch hier ist eine ausführliche Dokumentation wichtig – damit man den Überblick nicht verliert und schnell auf mögliche Fehler aufmerksam wird. </li>\n",
    "            <li><b>Validierung der mathematischen Lösung:</b> Die erhaltenen mathematischen Lösungen werden validiert. Dies kann bspw. durch den Vergleich mit gegebenen Testdaten und bekannten Beispielen geschehen. </li>\n",
    "            <li><b>Interpretation der Lösung im Hinblick auf das reale Problem:</b> Was bedeuten die berechneten Lösungen für unsere ursprüngliche Forschungsfrage? Inwieweit ist die Lösung angemessen?</li>\n",
    "        </ul>\n",
    "        <li><b>Zweiter Modellansatz:</b> Meist führt der erste Durchlauf durch den Modellierungsprozess nicht zu zufriedenstellenden Ergebnissen. Ggf. werden Daten hinzugenommen oder verworfen und neue Annahmen, Ansätze und Verbesserungen umgesetzt und beschrieben.</li>\n",
    "        <ul>\n",
    "            <li><b>Neue Modellannahmen / verworfene Vereinfachungen</b> </li>\n",
    "            <li><b>Beschreibung des modifizierten mathematischen Modells</b> </li>\n",
    "            <li><b>...</b> <i class=\"fas fa-sync\"></i>  </li>\n",
    "        </ul>\n",
    "        <li><b>Schlussfolgerung/Empfehlungen:</b> Abschließend wird die eingangs gestellte Forschungsfrage beantwortet. Dabei wird  Bezug zu den Ergebnissen des Modellierungsprozesses genommen.</li>\n",
    "         <ul> \n",
    "            <li><b>Ausblick:</b> Ideen für weitere Modellverbesserungen werden benannt.</li>\n",
    "     </ul>\n",
    "         \n",
    "Und nun viel Erfolg beim Nachvollziehen dieses Computational Essays!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Beschreibung des realen Problems  <i class=\"fa fa-globe\" style=\"font-size:26px\"></i>\n",
    "Netflix, Amazon und Co setzen bei der Kundenbindung vor allem auf eins: gute, auf den Nutzer zugeschnittene\n",
    "Empfehlungen für neue Produkte, Filme, Kleidung etc. Dazu entwickeln diese Unternehmen Empfehlungssysteme, die möglichst gut vorhersagen sollen, was dem jeweiligen Nutzer gefallen könnte. \n",
    "\n",
    "Um das eigene Empfehlungssystem weiter zu verbessern richtete Netflix 2006 eine Challenge aus: Das Team, welches mindestens 10 Prozent genauer vorhersagen kann, welche Filme einem Nutzer gefallen, hatte Chancen auf den Hauptpreis von 1.000.000 $. Netflix veröffentlichte im Rahmen der Challenge einen Datensatz mit den Bewertungen tausender Nutzer.\n",
    "\n",
    "Ziel unseres Projektes war es, bestmöglich vorherzusagen, wie ein/e Nutzer/in einen noch nicht bewerteten\n",
    "Film bewerten würde, um dann entsprechende Empfehlungen auszusprechen.\n",
    "\n",
    "## Forschungsfrage\n",
    "Die beiden zentralen Forschungsfragen, die wir im Rahmen unseres Projektes beantwortet werden sollen, lauten:\n",
    "\n",
    "* Wie können wir den Geschmack der Nutzer modellieren, indem wir vorhandene Nutzerbewertungen berücksichtigen?\n",
    "* Wie lassen sich unbekannte Nutzerbewertungen bestmöglich vorhersagen mit dem Ziel, basierend auf den vorhergesagten Bewertungen individuell passende neue Filme vorzuschlagen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Die Daten\n",
    "Alle Bewertungen, die die Nutzer für die Filme abgegeben haben, sind in einer Art Tabelle bzw. in einem rechteckigen Zahlenschema notiert. \n",
    "Jede Zeile steht für einen User und jede Spalte für einen Film. Die Einträge der Tabelle geben an, welche Bewertung ein Nutzer für einen Film abgegeben hat. Jedoch sind nicht alle Bewertungen bekannt.\n",
    "\n",
    "Ein Auszug aus der Tabelle könnte wie folgt aussehen:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"../figs/ratingmatrix_example.png\" width=\"500\"/> \n",
    "</div>\n",
    "\n",
    "<div class = \"alert alert-warning\">\n",
    "Es können auch Bilder, Abbildungen, Skizzen oder Videos in das Computational Essay integriert werden. Dies ist zum besseren Verständnis eurer Überlegungen und Ansätze oft hilfreich.\n",
    "</div>\n",
    "\n",
    " \n",
    "Der Netflixdatensatz besteht aus:\n",
    "* 17770 Filmen \n",
    "<i class=\"fa fa-film\"></i>  \n",
    "* 480189 Nutzern <i class=\"fa fa-user\"></i>  \n",
    "* 100480507 Bewertungen (engl. *ratings*) von 1 - 5 <i class=\"fa fa-star\"></i> <i class=\"fa fa-star\"></i> <i class=\"fa fa-star\"></i> <i class=\"fa fa-star\"></i> <i class=\"fa fa-star\"></i>\n",
    "\n",
    "\n",
    "Zur Beantwortung unserer Forschungfrage haben wir nicht mit dem ganzen Netflixdatensatz gearbeitet. Stattdessen liegt uns ein kleinerer Datensatz vor, basierend auf dem wir unser  Empfehlungsmodell entwickelt haben. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Für die Datenanalyse wird Zugriff auf einige Methoden aus externen Bibliotheken (= Sammlungen an Methoden, die man anwenden möchte, ohne sie noch einmal neu zu schreiben). Dazu führen wir im Folgenden einige Imports durch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-warning\">\n",
    "Die folgende Zelle ist eine Code-Zelle. Dort werden wichtige Bibliotheken geladen, die in diesem Jupyter Notebook verwendet werden. <br><br>\n",
    "    <b>pandas</b> ist eine Bibliothek, die statistische Methoden enthält. <br>\n",
    "    <b>numpy</b> ist eine Bibliothek, die ein einfacheres Umgehen mit großen Datenarrays ermöglicht.<br>\n",
    "    <b>matplotlib</b> ist eine Bibliothek, mit der Visualisierungen erstellt werden können.<br>\n",
    "    Mit <b>pd, np und plt</b> rufst Du die verschiedenen Bibliotheken auf.<br><br>\n",
    "    Bitte führe nun die folgende Code-Zelle aus, um die Bibliotheken zu laden! (Tipp: Das geht mit Shift+Enter!)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Bibliotheken laden\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Daten\n",
    "\n",
    "Hier werden die Daten in das Jupyter Notebook geladen. Wir lesen die Daten als sogenannte **npy-Dateien** ein.\n",
    "Es liegen zum einen Daten vor, die zur Entwicklung des Empfehlungssystems eingesetzt werden können. Diese Daten werden **Trainingsdaten** (oder Lerndaten) genannt. Zudem liegen Daten vor, die zum Testen des Empfehlungssystems eingesetzt werden können. Diese bezeichnen wir als **Testdaten**.\n",
    "\n",
    "Die Trainingsdaten speichern wir in <code>R_train</code> und die Testdaten in <code>R_test</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der Trainingsdaten\n",
    "R_train = np.load('../data/dataset_1/r_train.npy', allow_pickle=True)\n",
    "# Einlesen der Testdaten\n",
    "R_test = np.load('../data/dataset_1/r_test.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um zu überprüfen, ob das Einlesen der Daten funktioniert hat, lassen wir uns die beiden Datensätze ausgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Trainingsdaten\n",
    "print(R_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Testdaten\n",
    "print(R_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erste Erkundung der Daten und Datenvorbereitung <i class=\"fa fa-database\" style=\"font-size:26px\"></i> \n",
    "\n",
    "<div class = \"alert alert-warning\">\n",
    "Bei der Analyse der Daten stößt man vielfach auf Daten, die scheinbar fehlerhaft sind. Solche Daten werden aus dem Datensatz entfernt. Hier wird beschrieben, welche Datenvorbereitungsschritte durchgeführt werden. \n",
    "\n",
    "Zum Teil sind die Daten so komplex, dass es sinnvoll ist, nur einen ausgewählten Teil des Datensatzes zu betrachten. Hier wird genau beschrieben, welche Teildaten betrachtet wurden und nach welchen Kriterien dieses ausgewählt wurden.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf den ersten Blick scheint es, dass alle Einträge in <code>R_train</code> Null sind. Um zu überprüfen wie viele Bewertungen im Trainingsdatensatz vorhanden sind, lassen wir uns die Anzahl an Einträgen von <code>R_train</code> ausgeben, die größer Null sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl Einträge größer 0 (= Anzahl der bekannten Trainingsbewertungen)\n",
    "print(\"Anzahl Bewertungen im Trainingsdatensatz:\")\n",
    "np.sum(R_train > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analog bestimmen wir die Anzahl der gegebenen Bewertungen im Testdatensatz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl Einträge größer 0 (= Anzahl der bekannten Testbewertungen)\n",
    "print(\"Anzahl Bewertungen im Testdatensatz:\")\n",
    "np.sum(R_test > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir untersuchen, wie viele Nutzer und wie viele Filme im Trainings- und Testdatensatz enthalten sind. Dazu bestimmen wir die Anzahl der Zeilen und Spalten von <code>R_train</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualisieren der Trainingsdaten\n",
    "print(\"Anzahl User (= Zeilen) und Anzahl Movies (= Spalten) im Trainingsdatensatz:\")\n",
    "print(np.shape(R_train))\n",
    "\n",
    "# Visualisieren der Trainingsdaten\n",
    "print(\"Anzahl User (= Zeilen) und Anzahl Movies (= Spalten) im Testdatensatz:\")\n",
    "print(np.shape(R_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Anzahl der Nutzer und der Filme stimmt im Trainings- und Testdatensatz überein.\n",
    "Wir lassen uns exemplarisch ausgeben, wie viele Filme ein beliebiger Nutzer $i$ bewertet hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der bewerteten Filmes eines beliebigen Nutzers i\n",
    "i = 12 # i-ter Nutzer\n",
    "idx1 = np.where(R_train[i,:] > 0) # Suche alle Spalten, in denen Nutzer i einen Eintrag hat\n",
    "\n",
    "print(f\"Nutzer {i} hat folgende Filme bewertet:\")\n",
    "print(idx1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusätzlich untersuchen wir, wie viele Bewertungen pro Nutzern im ganzen Trainingsdatensatz auftreten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zählen der Anzahl der gegebenen Bewertungen pro Nutzer\n",
    "no_ratings_per_user = np.sum(~np.isnan(R_train), axis = 0) # axis = 0 gibt an, dass entlang der Zeilen (nicht Spalten) die Anzahl positiver Einträgen gezählt wird\n",
    "print(no_ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximale und minimale Anzahl Bewertungen pro Nutzer\n",
    "print(\"Maximale Anzahl Bewertungen pro Nutzer:\")\n",
    "print(np.max(no_ratings_per_user))\n",
    "\n",
    "print(\"Minimale Anzahl Bewertungen pro Nutzer:\")\n",
    "print(np.min(no_ratings_per_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einen besseren Überblick über die Verteilung der Bewertungen pro Nutzer liefert das folgende Histogramm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(no_ratings_per_user, bins=[1,5,10,20,30,40,50,60,100,150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erkenntnisse aus der Datenerkundung\n",
    "\n",
    "Es wird ersichtlich, dass die meisten Nutzer sehr wenige Bewertungen abgegeben haben.\n",
    "\n",
    "<div class = \"alert alert-warning\">\n",
    "Hier könnten weitere Beobachtungen und Erkenntnisse notiert werden.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Erster Modellansatz\n",
    "## Vereinfachungen und Modellannahmen\n",
    "Wir treffen zunächst folgende Annahmen: \n",
    "\n",
    "1. Wir nehmen an, dass eine fehlende Bewertung im Trainingsdatensatz bedeutet, dass der Nutzer den Film noch nicht gesehen hat. \n",
    "2. Wir nehmen an, dass alle Nutzer wahrheitsgemäß, d.h. entsprechend ihres tatsächlichen Geschmacks bewerten.\n",
    "\n",
    "## Entwicklung eines ersten mathematischen Modells\n",
    "Unser Ansatz ist es, Ähnlichkeiten zwischen Nutzern zu modellieren. Basierend auf den Bewertungen der **ähnlichsten Nutzer** werden wir dann Vorhersagen für fehlende Bewertungen berechnen. Zunächst wir jedoch ein Maß zur Quantifizierung von Ähnlichkeit benötigt.\n",
    "\n",
    "### Ähnlichkeitsmaß\n",
    "\n",
    "Konkret modellieren wir die Ähnlichkeit zwischen zwei beliebigen Nutzern über **die mittlere betragsmäßige Abweichung** der Bewertungen. Dabei werden nur die Filme berücksichtigt, die **beide** Nutzer bewertet haben\n",
    "\n",
    "**Beispiel:**\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"../figs/user_comparison.png\" width=\"300\"/> \n",
    " </div>\n",
    " \n",
    "\n",
    "$$S_{u_1, u_2} = \\frac{ |2 - 1 | + |4 - 2| + | 1 - 3 |}{3} = \\frac{5}{3}$$\n",
    "\n",
    "Hierbei ist $S_{u_1,u_2}$, der berechnete Ähnlichkeitswert von Nutzer $u_1$  und Nutzer $u_2$. \n",
    "\n",
    "\n",
    "**Allgemein: Berechnung der Ähnlichkeit für zwei beliebige Nutzer**\n",
    "\n",
    "$$ S_{u_1, u_2} = \\frac{1}{N_{u_1,u_2}} \\cdot \\sum_{j \\text{ mit } R_{u_1,j}, R_{u_2,j} > 0} (R_{u_1,j} - R_{u_2,j})$$\n",
    "\n",
    "\n",
    "Hierbei ist \n",
    "* $N_{u_1,u_2}$, die Anzahl der gemeinsamen bewerteten Filme von User $u_1$ und User $u_2$ \n",
    "* $R_{u_1,j}$, die  Bewertung von Nutzer $u_1$ für Film $j$  \n",
    "* $R_{u_2,j}$, die  Bewertung von Nutzer $u_2$ für Film $j$\n",
    " \n",
    "\n",
    "Die berechneten Ähnlichkeitswerte speichern wir für alle Nutzer in einer neuen Tabelle, der Ähnlichkeitstabelle $S$. Dieser Tabelle kann man schnell entnehmen, welche Nutzer sich besonders ähnlich sind. Je kleiner der Wert $S_{u_1,u_2}$, desto ähnlicher sind sich die beiden betrachteten Nutzer.\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"../figs/Rating_und_Aehnlichkeitstabelle.png\" width=\"1000\"/> \n",
    " </div>\n",
    " \n",
    "\n",
    "\n",
    "### Berechnung einer Vorhersage\n",
    "\n",
    "Um für einen beliebigen Nutzer $u_1$, der den Film $j$ noch nicht gesehen hat, eine Vorhersage zu berechnen gehen wir wie folgt vor:\n",
    "Wir suchen die $10$ (oder allgemeiner $k$) ähnlichsten Nutzer zu Nutzer $u_1$, die den Film $j$ bereits bewertet haben. \n",
    "Die vorhergesagte Bewertung berechnen wir dann über die mittlere Bewertung dieser $k$ ähnlichsten Nutzer:\n",
    "\n",
    "$$P_{u_1,j} = \\frac{\\sum_{u_i} R_{u_i,j}}{k}$$\n",
    "\n",
    "\n",
    "## Computergestützte Berechnungen\n",
    "\n",
    "Mithilfe von Python führen wir folgende Schritte durch:\n",
    "\n",
    "1. Berechne paarweise die Ähnlichkeit basierend auf der mittleren betragsmäßigen Abweichung.\n",
    "    \n",
    "2. Speichere die Ähnlichkeitswerte in einer neuen Ähnlichkeitstabelle S.\n",
    "    \n",
    "3. Für alle fehlenden Bewertungen $R_{i,j}$ in der Trainingstabelle:\n",
    "    * Berechne Vorhersage als Mittelwert der Bewertungen der $k$ ähnlichsten Nutzer, die den Film $j$ bewertet haben.\n",
    "    * Speichere die Vorhersagen in einer neuen Tabelle P (engl. *predicitions*).\n",
    "\n",
    "\n",
    "In folgender Codezelle, wird das beschriebene Modell zur Vorhersage der fehlenden Bewertungen umgesetzt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der paarweisen Ähnlichkeiten\n",
    "def similarity_user_based(R):\n",
    "    # Initialisiere die Ähnlichkeitstabelle mit nan-Einträgen\n",
    "    S =  np.ones((R.shape[0], R.shape[0])) * np.nan\n",
    "    \n",
    "    # Iteriere über alle Nutzer-Paare i und j\n",
    "    for i in range(R.shape[0]):\n",
    "        for j in range(R.shape[0]):\n",
    "            if i != j:\n",
    "                if np.count_nonzero(~np.isnan(R[i] - R[j])) > 0: # Prüfe, ob Nutzer i und j überhaupt Filme gemeinsam bewertet haben\n",
    "                    # Berechne mittlere betragsmäßige Abweichung für gemeinsam bewertete Filme\n",
    "                    S[i, j] = np.nansum(np.abs(R[i] - R[j])) / np.count_nonzero(~np.isnan(R[i] - R[j])) \n",
    "    return S\n",
    "\n",
    "S = similarity_user_based(R_train)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Berechnung der Vorhersage**\n",
    "\n",
    "Die Vorhersagen speichern wir in einer neuen Tabelle $P$ (von engl. predicion). \n",
    "Diese initialisieren wir in folgender Codezelle. Alle Einträge von P sind zunächst Null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm # Bibliothek zur Anzeige des Berechnungsfortschritts -- wird noch geloescht!\n",
    "\n",
    "def predict_ratings(R, S, k):\n",
    "    \n",
    "    '''\n",
    "    R = Trainingsdaten\n",
    "    S = Ähnlichkeitstabelle\n",
    "    k = Anzahl berücksichtigter nächster Nachbarn\n",
    "    '''\n",
    "    \n",
    "   # Initialisiere die Vorhersagetabelle P mit Nullen\n",
    "    P = np.zeros_like(R) # Tabelle P mit gleicher Größe wie R_train\n",
    "    \n",
    "    # Iteriere über alle Benutzer\n",
    "    for i in tqdm(range(R.shape[0])):\n",
    "        \n",
    "        # Sortiere die Ähnlichkeitstabelle für Nutzer i aufsteigend\n",
    "        sorted_similar_users = S[i].argsort() \n",
    "        \n",
    "        for j in range(R.shape[1]):\n",
    "            # Prüfe, ob Bewertung von User i für Film j fehlt\n",
    "            if np.isnan(R[i,j]):\n",
    "               \n",
    "                # Speichere die Filmbewertungen der k ähnlichsten User für Film j, sofern diese User den Film bewertet haben.\n",
    "                movie_ratings = [R[x, j] for x in sorted_similar_users if not np.isnan(R[x, j])][:k]\n",
    "                \n",
    "                # Prüfe, ob unter den k ähnlichsten Usern ein Nutzer den Film j bewertet hat.\n",
    "                if np.isnan(movie_ratings).all():\n",
    "                    P[i,j] = np.nan\n",
    "                else:\n",
    "                    # Berechne den Mittelwert aus den Bewertungen der k ähnlichsten Nutzer\n",
    "                    P[i,j] = np.nanmean(movie_ratings)\n",
    "    return P\n",
    "        \n",
    "P = predict_ratings(R_train, S, k=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe von P\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validierung der mathematischen Lösung\n",
    "\n",
    "Wir nutzen die Werte in der Tabelle `R_test` um zu bewerten, wie gut unser Modell die Bewertungen vorhersagt. Als Bewertungsmaß nutzen wir die **Wurzel der gemittelten Summe der Fehlerquadrate** (engl. *Root Mean Squared Error*, kurz RMSE).\n",
    "\n",
    "Diese lässt sich wie folgt berechnen:\n",
    "\n",
    "$$ \\sqrt{\\frac{1}{N} \\cdot \\left((R_{11} - P_{11})^2 + (R_{12} - P_{12})^2 + (R_{13} - P_{13})^2 + ... + (R_{NN} - P_{NN})^2\\right)}.$$\n",
    "\n",
    "Hierbei ist \n",
    "* $N$, die Anzahl der Bewertungen im Testdatensatz\n",
    "* $R_{ij}$, die bekannte Bewertung im Testdatensatz von Nutzer $i$ für Film $j$ \n",
    "* $P_{ij}$, die vorhergesagte Bewertung von Nutzer $i$ für Film $j$ \n",
    "\n",
    "In dieser Formel werden also nur die Einträge der Testmatrix $R_{ij}$ berücksichtigt, die tatsächlich bekannt sind.\n",
    "\n",
    "Wir nutzen das Summenzeichen, um die Formel kompakter darzustellen:\n",
    "\n",
    "$$\\sqrt{\\sum_{i,j: r_{ij} \\neq 0} \\frac{1}{N} (R_{ij} - P_{ij})^2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_RMSE(R,P):\n",
    "    idx = np.where(R>0) # Indizes bei denen R_test ≠ 0\n",
    "    N = np.sum(R > 0) # Anzahl Bewertungen im Testdatensatz\n",
    "    missing_prediction = np.count_nonzero(np.isnan(P[idx])) # Anzahl an Testdaten, für die keine Vorhersage vorliegt \n",
    "    \n",
    "    # Berechne Fehler zwischen tatsächlichen Bewertungen im Testdatensatz und Vorhersagen\n",
    "    error = np.sqrt(1/N * np.nansum((R[idx] - P[idx])**2))\n",
    "    print(f\"Fehler auf den Testdaten:\\n {error}\")\n",
    "    print(f\"\\nFür {missing_prediction/N*100} % der Testdaten wurde keine Vorhersage berechnet.\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung des Fehlers bezüglich der Testdaten\n",
    "compute_RMSE(R_test,P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation der Lösung\n",
    "\n",
    "Der Fehler bezüglich der Testdaten ist noch recht hoch. Zudem werden mit dem bisherigen Modell für viele Nutzer gar keine Vorhersagen berechnet. Für diese Nutzer können wir somit keine Filmempfehlungen aussprechen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Zweiter Modellansatz\n",
    "\n",
    "<div class = \"alert alert-warning\">\n",
    "In der Praxis, sowohl in Forschung als auch Wirtschaft, liefert der erste Durchgang durch den Modellierungskreislauf selten eine zufriedenstellende Lösung! Stattdessen ist es meist notwendig, einige Male durch den Modellierungskreislauf zu laufen und alle oder einzelne Schritte zu überdenken und erneut auszuführen.\n",
    "    \n",
    "In diesem Abschnitt werden Modellverbesserungen beschrieben, dokumentiert und umgesetzt.\n",
    "</div>\n",
    "\n",
    "\n",
    "## Modifiziertes Modell\n",
    "Um für alle fehlenden Bewertungen eine Vorhersage zu berechnen, modfizieren wir uns Modell. \n",
    "In den Fällen, in denen unser bisheriger Algorithmus keine Vorhersage berechnet, setzen wir die mittlere Bewertung des betrachteten Filmes als Vorhersage.\n",
    "\n",
    "\n",
    "**Beispiel:** Für den Nutzer $i$ und den Film $j$ konnte mit dem bisherigen *k-nächste Nachbarn*-Verfahren keine Vorhersage berechnet werden. Wir berechnen dann die mittlere Bewertung des Filmes $j$ über alle Nutzer, die diesen Film bewertet haben.  Anschließend setzen wir diesen Mittelwert als Vorhersage: \n",
    "\n",
    "\n",
    "$P_{i,j} = \\frac{1}{N_j} \\cdot \\sum_{i} R_{i,j}$\n",
    "\n",
    "Hierbei ist $N_j$ die Anzahl an Bewertungen, die für Film $j$ vorliegen. \n",
    "\n",
    "Das modifizierte Verfahren wird in der folgenden Codezelle umgesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_with_movie_mean(R, S, k):\n",
    "    \n",
    "    '''\n",
    "    R = Trainingsdaten\n",
    "    S = Ähnlichkeitstabelle\n",
    "    k = Anzahl berücksichtigter nächster Nachbarn\n",
    "    '''\n",
    "    \n",
    "   # Initialisiere die Vorhersagetabelle P mit Nullen\n",
    "    P = np.zeros_like(R) # Tabelle P mit gleicher Größe wie R_train\n",
    "    movie_mean_value = np.nanmean(R, axis = 0) \n",
    "    movie_mean_value[np.isnan(movie_mean_value)] = np.nanmean(R) #  np.nanmean ignoriert nan-Einträge bei Berechnung des Mittelwerts\n",
    "    \n",
    "    # Iteriere über alle Benutzer\n",
    "    for i in tqdm(range(R.shape[0])):\n",
    "        \n",
    "        # Sortiere die Ähnlichkeitstabelle für Nutzer i aufsteigend\n",
    "        sorted_similar_users = S[i].argsort()\n",
    "        \n",
    "        for j in range(R.shape[1]):\n",
    "            # Prüfe, ob Bewertung von User i für Film j fehlt\n",
    "            if np.isnan(R[i,j]):\n",
    "                # Speichere die Filmbewertungen der k ähnlichsten User für Film j, sofern User den Film bewertet hat.\n",
    "                movie_ratings = [R[x, j] for x in sorted_similar_users if not np.isnan(R[x, j])][:k]\n",
    "                \n",
    "                if np.isnan(movie_ratings).all():\n",
    "                    # Falls keine Vorhersage berechnet werden kann, setze mittlere Bewertung des Filmes j als Vorhersage\n",
    "                    P[i,j] = movie_mean_value[j] \n",
    "                else:\n",
    "                    # Sonst berechne mittlere Bewertung der k ähnlichsten Nutzer\n",
    "                    P[i,j] = np.nanmean(movie_ratings)\n",
    "    return P\n",
    "        \n",
    "P = predict_ratings_with_movie_mean(R_train, S, k=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Der Fehler auf den Testdaten beträgt dann:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_RMSE(R_test,P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Fehler auf den Testdaten ist nun ...\n",
    "<div class = \"alert alert-warning\">\n",
    "Hier sollte der Fehler eingeordnet werden. Ist er geringer oder größer? Woran kann dies liegen?\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class = \"alert alert-warning\">\n",
    "... <i class=\"fas fa-sync\"></i> ... <br>\n",
    "    Hier sollten weitere Abschnitte (Interpretation der neuen Ergebnisse im Hinblick auf das reale Problem oder ggf. weitere Modellansätze) folgen.\n",
    "</div>\n",
    "\n",
    "# V. Schlussfolgerung / Empfehlungen \n",
    "\n",
    "<div class = \"alert alert-warning\">\n",
    "Hier wird der gesamte Modellierungs- und Programmierprozess im Hinblick auf das reale Problem resümiert. Zentrale Erkenntnisse und Hinweise an die oder den Problemstellenden werden zusammengefasst.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausblick\n",
    "<div class = \"alert alert-warning\">\n",
    "Hier werden mögliche weitere Modellverbesserungsideen beschrieben, die im Rahmen des Projektes (bspw. aus Zeitgründen, wegen fehlender Daten o.ä.) nicht umgesetzt werden konnten.\n",
    "</div>\n",
    "\n",
    "* Die Berechnung einer Vorhersage erfolgt bisher über die mittlere Bewertung der $k$ ähnlichsten User. Die Bewertungen der $k$ ähnlichsten Nutzer könnten zusätzlich gemäß ihrer Ähnlichkeit gewichtet werden. Die Vorhersage wird dann über einen **gewichteten Mittelwert** berechnet. \n",
    "* Andere Ähnlichkeitsmaße könnten hergeleitet und getestet werden. Zum Beispiel ...\n",
    "* Weiterhin wäre es sinnvoll, den Wert für den Parameter $k$ zu optimieren. Dazu könnte man ...\n",
    "* ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
